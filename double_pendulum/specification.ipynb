{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b1172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-04-25 01:11:55,085:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-04-25 01:11:55,085 - jax._src.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:2025-04-25 01:11:55,101:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': UNIMPLEMENTED: LoadPjrtPlugin is not implemented on windows yet.\n",
      "2025-04-25 01:11:55,101 - jax._src.xla_bridge - INFO - Unable to initialize backend 'tpu': UNIMPLEMENTED: LoadPjrtPlugin is not implemented on windows yet.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find the mathematical function skeleton that represents acceleration in a damped nonlinear oscillator system with driving force, given data on time, position, and velocity. \n",
    "\"\"\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap, config\n",
    "import pyswarms as ps\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_platform_name\", \"cpu\")\n",
    "import numpy as np\n",
    "import jax.random as random\n",
    "from jaxopt import LBFGS\n",
    "\n",
    "MAX_NPARAMS = 10\n",
    "initial_params = jnp.ones(MAX_NPARAMS, dtype=jnp.float64)\n",
    "\n",
    "\n",
    "def evaluate(data: dict, params=initial_params) -> dict:\n",
    "\n",
    "    master_key = random.PRNGKey(0)\n",
    "    inputs, outputs = data['inputs'], data['outputs']\n",
    "    n_dim = inputs.shape[1] // 2\n",
    "    q, p = inputs[:, :n_dim], inputs[:, n_dim:]\n",
    "    true_value = outputs\n",
    "    \n",
    "    @jit\n",
    "    def compute_dynamics(q, p, params):\n",
    "        def hamiltonian(q, p, params):\n",
    "            return equation(q, p, params)  \n",
    "        q_dot = jax.grad(hamiltonian, 1)(q, p, params)  \n",
    "        p_dot = -jax.grad(hamiltonian, 0)(q, p, params)  \n",
    "        return jnp.concatenate([q_dot, p_dot])\n",
    "\n",
    "    batch_compute_dynamics = jit(vmap(compute_dynamics, (0, 0, None)))\n",
    "\n",
    "    @jit\n",
    "    def loss_fn(params):\n",
    "        pred = batch_compute_dynamics(q, p, params)\n",
    "        return jnp.mean(jnp.square(pred - true_value))\n",
    "    \n",
    "    def run_optimization(objective_fn, initial_guess, key, num_pso_runs=5, pso_iters=300, swarmsize=100, gg = False):\n",
    "        print(f\"Initial guess size: {initial_guess.size}, MAX_NPARAMS: {MAX_NPARAMS}\")\n",
    "\n",
    "        grads   = jax.grad(equation,2)(q[1],p[1],params)           # (MAX_NPARAMS,)           \n",
    "        active  = jnp.where(jnp.abs(grads) > 0)[0]        # e.g. [0,1,2,3,4,5,6,7]\n",
    "        n_params = active.shape[0]                        # 只保留活跃参数\n",
    "        print(n_params)\n",
    "        \n",
    "        solver = LBFGS(objective_fn, maxiter=100, tol=1e-8)\n",
    "\n",
    "        if  gg == True:\n",
    "            result =  solver.run(initial_guess)\n",
    "            return result.params\n",
    "        else:\n",
    "            # --- Use pyswarms with JAX-controlled initial positions ---\n",
    "            @jit\n",
    "            def pso_objective_wrapper(particles_matrix):\n",
    "                return vmap(objective_fn)(particles_matrix)\n",
    "\n",
    "            min_bound_np = np.full(n_params, -100.0, dtype=np.float64)\n",
    "            max_bound_np = np.full(n_params, 100.0, dtype=np.float64)\n",
    "            bounds = (min_bound_np, max_bound_np)\n",
    "\n",
    "            options = {'c1': 1.49445, 'c2': 1.49445, 'w': 0.729}\n",
    "\n",
    "            best_pso_params = None\n",
    "            best_pso_loss = jnp.inf\n",
    "\n",
    "            current_key = key # Use the passed-in key\n",
    "\n",
    "            print(f\"Running pyswarms PSO {num_pso_runs} times with unique initial swarms...\")\n",
    "            for i in range(num_pso_runs):\n",
    "                # Split the key for this run to ensure unique randomness\n",
    "                current_key, subkey = random.split(current_key)\n",
    "\n",
    "                # Generate initial positions using JAX PRNG within bounds\n",
    "                # Use jnp arrays for min/max bounds in jax.random.uniform\n",
    "                min_bound_jnp = jnp.full(n_params, -10.0, dtype=jnp.float64)\n",
    "                max_bound_jnp = jnp.full(n_params, 10.0, dtype=jnp.float64)\n",
    "                init_pos_jax = random.uniform(subkey,\n",
    "                                              shape=(swarmsize, n_params),\n",
    "                                              dtype=jnp.float64,\n",
    "                                              minval=min_bound_jnp,\n",
    "                                              maxval=max_bound_jnp)\n",
    "                # Convert to NumPy array for pyswarms\n",
    "                init_pos_np = np.array(init_pos_jax)\n",
    "\n",
    "                print(f\"  PSO Run {i+1}/{num_pso_runs} (using JAX key split for init_pos)\")\n",
    "                optimizer = ps.single.GlobalBestPSO(n_particles=swarmsize,\n",
    "                                                     dimensions=n_params,\n",
    "                                                     options=options,\n",
    "                                                     bounds=bounds,\n",
    "                                                     # Pass the generated initial positions\n",
    "                                                     init_pos=init_pos_np) # <-- Pass init_pos here\n",
    "\n",
    "                # Perform optimization (pyswarms will use the provided init_pos)\n",
    "                current_pso_loss, current_pso_params = optimizer.optimize(\n",
    "                    pso_objective_wrapper,\n",
    "                    iters=pso_iters,\n",
    "                    verbose=False\n",
    "                )\n",
    "                current_pso_params = jnp.array(current_pso_params, dtype=jnp.float64)\n",
    "\n",
    "                print(f\"    Run {i+1} completed. Loss: {current_pso_loss}\")\n",
    "                if current_pso_loss < best_pso_loss:\n",
    "                    best_pso_loss = current_pso_loss\n",
    "                    best_pso_params = current_pso_params\n",
    "                    print(f\"    New best PSO loss found: {best_pso_loss}\")\n",
    "\n",
    "            # ... (rest of the function: handling no solution, BFGS refinement) ...\n",
    "            if best_pso_params is None:\n",
    "                 print(\"Warning: PSO did not find any valid solution after multiple runs. Using initial guess for BFGS.\")\n",
    "                 best_pso_params = initial_guess # Fallback\n",
    "\n",
    "            print(f\"\\nBest PSO loss after {num_pso_runs} runs: {best_pso_loss}\")\n",
    "            print(\"Refining best PSO result with L- BFGS...\")\n",
    "\n",
    "            result =  solver.run(best_pso_params)\n",
    "            \n",
    "            return result.params\n",
    "\n",
    "    \n",
    "    def calculate_sensitivities(opt_params: jnp.ndarray, base_loss: float) -> jnp.ndarray:\n",
    "        n_active = opt_params.size\n",
    "        masks = 1.0 - jnp.eye(n_active, dtype=opt_params.dtype)\n",
    "        @jit\n",
    "        def solve_one(mask_i):\n",
    "            init = opt_params * mask_i\n",
    "            def sub_loss(p):\n",
    "                return loss_fn(p * mask_i)\n",
    "            solver = LBFGS(fun=sub_loss, maxiter=100, tol=1e-8)\n",
    "            out    = solver.run(init)         \n",
    "            loss_i = loss_fn(out.params * mask_i)       \n",
    "            return jnp.log2(loss_i / base_loss)\n",
    "\n",
    "        sensitivities = vmap(solve_one)(masks)\n",
    "        return sensitivities\n",
    "\n",
    "    try:\n",
    "        opt_key, sensi_key = random.split(master_key)\n",
    "        optimized_params = run_optimization(loss_fn, params, key=opt_key)\n",
    "        final_loss = loss_fn(optimized_params)\n",
    "        print(f\"Final loss after L-BFGS: {final_loss}\")\n",
    "        if optimized_params is None:\n",
    "             print(\"Optimization failed to produce parameters.\")\n",
    "             return None\n",
    "\n",
    "        final_loss = loss_fn(optimized_params)\n",
    "        print(f\"Final optimized loss: {final_loss}\")\n",
    "    except Exception as e:\n",
    "        # ... (error handling remains the same) ...\n",
    "        print(f\"Optimization or final loss calculation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "    if not jnp.isfinite(final_loss):\n",
    "        print(\"Final loss is not finite.\")\n",
    "        return None\n",
    "\n",
    "    # Pass a key to sensitivity analysis if it also needs randomness\n",
    "    # For now, assuming calculate_sensitivities doesn't need a separate key\n",
    "    sensitivities = calculate_sensitivities(optimized_params, final_loss)\n",
    "    sensitivity_dict = {f\"sensitive of params[{i}]\": round(float(sensitivities[i]), 4) \n",
    "                       for i in range(len(sensitivities))}\n",
    "\n",
    "\n",
    "    return {\n",
    "        'params': optimized_params,\n",
    "        'loss': final_loss,\n",
    "        'sensitivities': sensitivity_dict\n",
    "    }\n",
    "\n",
    "@jit\n",
    "def equation(q: jnp.array, p: jnp.array, params: jnp.array) -> jnp.array:\n",
    "    q1, q2 = q[...,0], q[...,1]\n",
    "    p1, p2 = p[...,0], p[...,1]\n",
    "\n",
    "    T_num = (params[0] * p1**2 + params[1] * p2**2 + params[2] * p1 * p2)\n",
    "    T_den = params[3] + params[4] * jnp.cos(q1 - q2) \n",
    "    T = T_num / T_den\n",
    "\n",
    "    # Potential Energy (V)\n",
    "    V = params[5]* jnp.cos(q1) - params[6] * jnp.cos(q2)\n",
    "\n",
    "    return T + V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31f02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.        ]\n",
      " [-0.0654109  -0.03270545]\n",
      " [-0.1308218  -0.0654109 ]\n",
      " ...\n",
      " [ 8.65638418  3.16140084]\n",
      " [ 8.57651316  3.21913912]\n",
      " [ 8.49518264  3.27744751]]\n",
      "[[  1.57079633   1.57079633]\n",
      " [  1.57074181   1.57079633]\n",
      " [  1.57057825   1.57079633]\n",
      " ...\n",
      " [  0.72130633 -25.8504519 ]\n",
      " [  0.73509878 -25.84159421]\n",
      " [  0.74876059 -25.83246209]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Initial guess size: 10, MAX_NPARAMS: 10\n",
      "7\n",
      "Running pyswarms PSO 5 times with unique initial swarms...\n",
      "  PSO Run 1/5 (using JAX key split for init_pos)\n",
      "    Run 1 completed. Loss: 24.169338790776283\n",
      "    New best PSO loss found: 24.169338790776283\n",
      "  PSO Run 2/5 (using JAX key split for init_pos)\n",
      "    Run 2 completed. Loss: 24.169338790770542\n",
      "    New best PSO loss found: 24.169338790770542\n",
      "  PSO Run 3/5 (using JAX key split for init_pos)\n",
      "    Run 3 completed. Loss: 24.16933879077056\n",
      "  PSO Run 4/5 (using JAX key split for init_pos)\n",
      "    Run 4 completed. Loss: 24.169338790770542\n",
      "  PSO Run 5/5 (using JAX key split for init_pos)\n",
      "    Run 5 completed. Loss: 24.16933879077058\n",
      "\n",
      "Best PSO loss after 5 runs: 24.169338790770542\n",
      "Refining best PSO result with L- BFGS...\n",
      "Final loss after L-BFGS: 24.169338790770542\n",
      "Final optimized loss: 24.169338790770542\n",
      "最终损失值 (MSE): {'params': Array([  2.87598104, -11.43787486,  -5.19137516,  -1.9833889 ,\n",
      "       -14.46307374,  -0.02864757,  -7.07546704], dtype=float64), 'loss': Array(24.16933879, dtype=float64), 'sensitivities': {'sensitive of params[0]': 0.0, 'sensitive of params[1]': 0.0, 'sensitive of params[2]': 0.0, 'sensitive of params[3]': 0.0, 'sensitive of params[4]': 0.0, 'sensitive of params[5]': nan, 'sensitive of params[6]': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 读取 CSV 文件并转换为 NumPy 数组\n",
    "data0 = pd.read_csv('../double_pendulum/double_pendulum_high_precision.csv')\n",
    "#data0 = pd.read_csv('./hamiltonian_spring_mass_energy_data.csv')\n",
    "tae = data0.to_numpy()\n",
    "\n",
    "# 使用 JAX 的数组操作替换 PyTorch 的操作\n",
    "state = jnp.array(tae[:, 1:3], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "true_q_ddot = jnp.array(tae[:, 3:-1], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "energy = jnp.array(tae[:, -1], dtype=jnp.float64)\n",
    "print(true_q_ddot)\n",
    "print(state)\n",
    "# 将数据存储在字典中\n",
    "data = {\n",
    "    'inputs': state,\n",
    "    'outputs': true_q_ddot,  # 真实的加速度\n",
    "    'energy': energy\n",
    "}\n",
    "\n",
    "\n",
    "print(initial_params)\n",
    "# 评估并优化参数\n",
    "final_loss = evaluate(data, initial_params)\n",
    "print(\"最终损失值 (MSE):\", final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446c57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
