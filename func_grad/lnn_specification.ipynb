{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0971bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import config, grad, jit, vmap\n",
    "import numpy as np\n",
    "from pyswarm import pso\n",
    "from jax.scipy.optimize import minimize\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "MAX_NPARAMS = 10\n",
    "initial_params = [jnp.array(1.0)]*MAX_NPARAMS\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(data: dict, params=initial_params) -> float:\n",
    "\n",
    "    inputs, outputs = data['inputs'], data['outputs']\n",
    "    n_dim = inputs.shape[1] // 2\n",
    "    q = inputs[:, :n_dim]\n",
    "    q_t = inputs[:, n_dim:]\n",
    "    true_accelerations = outputs\n",
    "\n",
    "\n",
    "    # 修改：将lagrangian直接嵌入compute_acceleration中，避免将函数作为参数传递\n",
    "    @jit\n",
    "    def compute_acceleration(q, q_t, params):\n",
    "        # 直接使用equation函数而不是传递lagrangian函数\n",
    "        \n",
    "        # 预先计算梯度\n",
    "        @jit\n",
    "        def lag(q_single, q_t_single, params):\n",
    "            # 确保对单个样本调用时返回标量\n",
    "            result = equation(q_single, q_t_single, params)\n",
    "            # 如果结果是数组，取和或平均值来确保返回标量\n",
    "            return jnp.sum(result)\n",
    "            \n",
    "        # 计算二阶导数\n",
    "        hessian_q_t = jax.hessian(lag, 1)(q, q_t, params)\n",
    "        grad_q = jax.grad(lag, 0)(q, q_t, params)\n",
    "        jacobian_q_q_t = jax.jacobian(jax.grad(lag, 1), 0)(q, q_t, params)\n",
    "        q_tt = jnp.linalg.pinv(hessian_q_t) @ (grad_q - jacobian_q_q_t @ q_t)\n",
    "        return q_tt\n",
    "\n",
    "    # 使用vmap批处理\n",
    "    batch_compute_acceleration = jit(vmap(compute_acceleration, in_axes=(0, 0, None)))\n",
    "\n",
    "    # 使用jit装饰器优化损失函数\n",
    "    @jit\n",
    "    def loss_fn(params):\n",
    "        predicted_accelerations = batch_compute_acceleration(q, q_t, params)\n",
    "        return jnp.mean(jnp.square(predicted_accelerations - true_accelerations))\n",
    "    \n",
    "    #return loss_fn(params)\n",
    "\n",
    "    # 针对numpy数组的包装函数\n",
    "    def objective(params):\n",
    "        try:\n",
    "            params = jnp.array(params)  # 确保转换为JAX数组\n",
    "            loss_value = loss_fn(params)\n",
    "            return float(loss_value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in objective function: {e}\")\n",
    "            # 返回一个大的损失值，避免优化器选择这个点\n",
    "            return 1e10\n",
    "\n",
    "    # 粒子群优化的参数\n",
    "    lb = [-1.0] * len(initial_params)  # 参数下限\n",
    "    ub = [10.0] * len(initial_params)   # 参数上限\n",
    "\n",
    "    # 调用 pso 函数进行优化\n",
    "    optimized_params, optimized_loss = pso(objective, lb, ub, swarmsize=30, maxiter=500)\n",
    "\n",
    "    print(\"pso Optimized parameters:\", optimized_params)\n",
    "    print(\"pso Optimized loss:\", optimized_loss)\n",
    "\n",
    "    # 使用JAX的优化器进一步优化\n",
    "    loss_partial = jit(loss_fn)  # 确保JIT编译\n",
    "    result = minimize(loss_partial, optimized_params, method='BFGS', options={'maxiter': 1000})\n",
    "    optimized_params = result.x\n",
    "    loss = result.fun\n",
    "\n",
    "    if jnp.isnan(loss) or jnp.isinf(loss):\n",
    "        return None\n",
    "    else:\n",
    "        print(optimized_params)\n",
    "        return -loss.item()\n",
    "\n",
    "'''\n",
    "@jit  # 添加JIT装饰器\n",
    "def equation(q: jnp.array, q_t: jnp.array, params: jnp.array) -> jnp.array:\n",
    "    \"\"\" Mathematical function for lagrangian in a one-dimensional physical system\n",
    "    Args:\n",
    "        q (jnp.array): observation of current generalized coordinate.\n",
    "        q_t (jnp.array): observation of generalized velocity.\n",
    "        params (jnp.array): List of numeric constants or parameters to be optimized.\n",
    "    Returns:\n",
    "        jnp.array: lagrangian as the result of applying the mathematical function to the inputs.\n",
    "    \"\"\" \n",
    "    \n",
    "\n",
    "    T =  1/(jnp.sqrt(1-params[0]*q_t**2))-params[1]\n",
    "    V =  params[3]*q   \n",
    "    \n",
    "\n",
    "    return T - V'''\n",
    "\n",
    "\n",
    "@jit\n",
    "def equation(q: jnp.array, q_t: jnp.array, params: jnp.array):\n",
    "\n",
    "    #q = q[...,0]\n",
    "    #q_t = q_t[...,0]\n",
    "    T = 1/(jnp.sqrt(1-q_t**2))-params[1]\n",
    "    V = -params[3]*q   \n",
    "    \n",
    "    result = T - V\n",
    "    '''# 确保返回标量\n",
    "    if hasattr(result, 'shape') and result.shape == (1,):\n",
    "        return result[0]  # 返回标量而不是数组'''\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "681489a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "[[0.15145342]\n",
      " [0.15184868]\n",
      " [0.1522456 ]\n",
      " [0.1526442 ]\n",
      " [0.15304448]\n",
      " [0.15344645]\n",
      " [0.15385011]\n",
      " [0.15425547]\n",
      " [0.15466253]\n",
      " [0.1550713 ]\n",
      " [0.15548178]\n",
      " [0.15589401]\n",
      " [0.156308  ]\n",
      " [0.15672377]\n",
      " [0.15714133]\n",
      " [0.15756067]\n",
      " [0.15798181]\n",
      " [0.15840475]\n",
      " [0.15882949]\n",
      " [0.15925604]\n",
      " [0.15968441]\n",
      " [0.16011402]\n",
      " [0.16054629]\n",
      " [0.16098041]\n",
      " [0.16141639]\n",
      " [0.16185423]\n",
      " [0.16229395]\n",
      " [0.16273556]\n",
      " [0.16317907]\n",
      " [0.16362449]\n",
      " [0.16407184]\n",
      " [0.16452113]\n",
      " [0.16497238]\n",
      " [0.16542561]\n",
      " [0.16588084]\n",
      " [0.16633806]\n",
      " [0.1667973 ]\n",
      " [0.16725858]\n",
      " [0.16772189]\n",
      " [0.16818726]\n",
      " [0.1686547 ]\n",
      " [0.16912421]\n",
      " [0.16959583]\n",
      " [0.17006955]\n",
      " [0.17054539]\n",
      " [0.17102337]\n",
      " [0.1715035 ]\n",
      " [0.17198579]\n",
      " [0.17247026]\n",
      " [0.17295691]\n",
      " [0.17344577]\n",
      " [0.17393685]\n",
      " [0.17443015]\n",
      " [0.17492571]\n",
      " [0.17542352]\n",
      " [0.1759236 ]\n",
      " [0.17642598]\n",
      " [0.17693065]\n",
      " [0.17743765]\n",
      " [0.17794697]\n",
      " [0.17845864]\n",
      " [0.17897267]\n",
      " [0.17948907]\n",
      " [0.18000786]\n",
      " [0.18052907]\n",
      " [0.1810527 ]\n",
      " [0.18157877]\n",
      " [0.18210731]\n",
      " [0.18263831]\n",
      " [0.1831718 ]\n",
      " [0.1837078 ]\n",
      " [0.18424632]\n",
      " [0.18478738]\n",
      " [0.18533098]\n",
      " [0.18587716]\n",
      " [0.18642592]\n",
      " [0.18697728]\n",
      " [0.18753126]\n",
      " [0.18808788]\n",
      " [0.18864714]\n",
      " [0.18920907]\n",
      " [0.18977368]\n",
      " [0.190341  ]\n",
      " [0.19091103]\n",
      " [0.19148379]\n",
      " [0.19205931]\n",
      " [0.1926376 ]\n",
      " [0.19321867]\n",
      " [0.19380254]\n",
      " [0.19438923]\n",
      " [0.19497877]\n",
      " [0.19557115]\n",
      " [0.19616641]\n",
      " [0.19676457]\n",
      " [0.19736563]\n",
      " [0.19796962]\n",
      " [0.19857657]\n",
      " [0.19918652]\n",
      " [0.19979948]\n",
      " [0.20041548]\n",
      " [0.20103453]\n",
      " [0.20165665]\n",
      " [0.20228187]\n",
      " [0.20291021]\n",
      " [0.20354168]\n",
      " [0.20417631]\n",
      " [0.20481412]\n",
      " [0.20545513]\n",
      " [0.20609936]\n",
      " [0.20674684]\n",
      " [0.20739757]\n",
      " [0.2080516 ]\n",
      " [0.20870893]\n",
      " [0.20936959]\n",
      " [0.21003361]\n",
      " [0.21070099]\n",
      " [0.21137178]\n",
      " [0.21204598]\n",
      " [0.21272362]\n",
      " [0.21340473]\n",
      " [0.21408932]\n",
      " [0.21477743]\n",
      " [0.21546906]\n",
      " [0.21616426]\n",
      " [0.21686303]\n",
      " [0.2175654 ]\n",
      " [0.2182714 ]\n",
      " [0.21898105]\n",
      " [0.21969744]\n",
      " [0.22041416]\n",
      " [0.22113467]\n",
      " [0.22185901]\n",
      " [0.2225872 ]\n",
      " [0.22331926]\n",
      " [0.22405522]\n",
      " [0.22479511]\n",
      " [0.22553895]\n",
      " [0.22628677]\n",
      " [0.2270386 ]\n",
      " [0.22779446]\n",
      " [0.22855437]\n",
      " [0.22931837]\n",
      " [0.23008649]\n",
      " [0.23085874]\n",
      " [0.23163517]\n",
      " [0.23241579]\n",
      " [0.23320063]\n",
      " [0.23398973]\n",
      " [0.23478311]\n",
      " [0.2355808 ]\n",
      " [0.23638283]\n",
      " [0.23718924]\n",
      " [0.23800004]\n",
      " [0.23881527]\n",
      " [0.23963497]\n",
      " [0.24045915]\n",
      " [0.24128786]\n",
      " [0.24212112]\n",
      " [0.24295896]\n",
      " [0.24380142]\n",
      " [0.24464853]\n",
      " [0.24550036]\n",
      " [0.24635695]\n",
      " [0.24721832]\n",
      " [0.24808452]\n",
      " [0.24895559]\n",
      " [0.24983156]\n",
      " [0.25071246]\n",
      " [0.25159834]\n",
      " [0.25248924]\n",
      " [0.2533852 ]\n",
      " [0.25428624]\n",
      " [0.25519242]\n",
      " [0.25610378]\n",
      " [0.25702034]\n",
      " [0.25794217]\n",
      " [0.25886929]\n",
      " [0.25980175]\n",
      " [0.26073959]\n",
      " [0.26168285]\n",
      " [0.26263158]\n",
      " [0.26358582]\n",
      " [0.26454561]\n",
      " [0.265511  ]\n",
      " [0.26648204]\n",
      " [0.26745877]\n",
      " [0.26844123]\n",
      " [0.26942947]\n",
      " [0.27042354]\n",
      " [0.27142349]\n",
      " [0.27242936]\n",
      " [0.2734412 ]\n",
      " [0.27445907]\n",
      " [0.275483  ]\n",
      " [0.27651305]\n",
      " [0.27754927]\n",
      " [0.27859172]\n",
      " [0.27964043]\n",
      " [0.28069548]\n",
      " [0.2817569 ]\n",
      " [0.28282476]\n",
      " [0.28389911]\n",
      " [0.28498   ]\n",
      " [0.28606748]\n",
      " [0.28716162]\n",
      " [0.28826247]\n",
      " [0.28937009]\n",
      " [0.29048452]\n",
      " [0.29160584]\n",
      " [0.2927341 ]\n",
      " [0.29386935]\n",
      " [0.29501166]\n",
      " [0.29616109]\n",
      " [0.2973177 ]\n",
      " [0.29848155]\n",
      " [0.29965269]\n",
      " [0.30083121]\n",
      " [0.30201715]\n",
      " [0.30321058]\n",
      " [0.30441156]\n",
      " [0.30562017]\n",
      " [0.30683647]\n",
      " [0.30806051]\n",
      " [0.30929238]\n",
      " [0.31053214]\n",
      " [0.31177985]\n",
      " [0.31303559]\n",
      " [0.31429942]\n",
      " [0.31557142]\n",
      " [0.31685166]\n",
      " [0.31814021]\n",
      " [0.31943713]\n",
      " [0.32074252]\n",
      " [0.32205643]\n",
      " [0.32337895]\n",
      " [0.32471016]\n",
      " [0.32605017]\n",
      " [0.32739904]\n",
      " [0.32875687]\n",
      " [0.33012373]\n",
      " [0.33149971]\n",
      " [0.33288488]\n",
      " [0.33427934]\n",
      " [0.33568317]\n",
      " [0.33709645]\n",
      " [0.33851927]\n",
      " [0.33995173]\n",
      " [0.3413939 ]\n",
      " [0.34284589]\n",
      " [0.34430777]\n",
      " [0.34577964]\n",
      " [0.3472616 ]\n",
      " [0.34875374]\n",
      " [0.35025615]\n",
      " [0.35176893]\n",
      " [0.35329218]\n",
      " [0.35482599]\n",
      " [0.35637046]\n",
      " [0.3579257 ]\n",
      " [0.3594918 ]\n",
      " [0.36106886]\n",
      " [0.36265699]\n",
      " [0.3642563 ]\n",
      " [0.36586688]\n",
      " [0.36748885]\n",
      " [0.36912231]\n",
      " [0.37076737]\n",
      " [0.37242413]\n",
      " [0.37409273]\n",
      " [0.37577325]\n",
      " [0.37746582]\n",
      " [0.37917055]\n",
      " [0.38088758]\n",
      " [0.38261706]\n",
      " [0.38435912]\n",
      " [0.38611389]\n",
      " [0.3878815 ]\n",
      " [0.38966208]\n",
      " [0.39145575]\n",
      " [0.39326264]\n",
      " [0.39508291]\n",
      " [0.39691666]\n",
      " [0.39876406]\n",
      " [0.40062522]\n",
      " [0.4025003 ]\n",
      " [0.40438944]\n",
      " [0.40629277]\n",
      " [0.40821045]\n",
      " [0.41014262]\n",
      " [0.41208944]\n",
      " [0.41405104]\n",
      " [0.41602758]\n",
      " [0.41801923]\n",
      " [0.42002612]\n",
      " [0.42204843]\n",
      " [0.4240863 ]\n",
      " [0.42613991]\n",
      " [0.42820942]\n",
      " [0.43029498]\n",
      " [0.43239677]\n",
      " [0.43451496]\n",
      " [0.43664971]\n",
      " [0.43880121]\n",
      " [0.44096964]\n",
      " [0.44315524]\n",
      " [0.44535819]\n",
      " [0.4475787 ]\n",
      " [0.44981694]\n",
      " [0.45207311]\n",
      " [0.45434742]\n",
      " [0.45664006]\n",
      " [0.45895123]\n",
      " [0.46128114]\n",
      " [0.46362999]\n",
      " [0.46599799]\n",
      " [0.46838536]\n",
      " [0.47079231]\n",
      " [0.47321907]\n",
      " [0.47566584]\n",
      " [0.47813285]\n",
      " [0.48062034]\n",
      " [0.48312852]\n",
      " [0.48565763]\n",
      " [0.48820791]\n",
      " [0.49077959]\n",
      " [0.49337292]\n",
      " [0.49598813]\n",
      " [0.49862548]\n",
      " [0.50128522]\n",
      " [0.50396759]\n",
      " [0.50667286]\n",
      " [0.50940128]\n",
      " [0.51215312]\n",
      " [0.51492864]\n",
      " [0.51772814]\n",
      " [0.52055198]\n",
      " [0.52340046]\n",
      " [0.52627387]\n",
      " [0.52917252]\n",
      " [0.53209671]\n",
      " [0.53504675]\n",
      " [0.53802294]\n",
      " [0.54102561]\n",
      " [0.54405509]\n",
      " [0.54711168]\n",
      " [0.55019573]\n",
      " [0.55330758]\n",
      " [0.55644756]\n",
      " [0.55961601]\n",
      " [0.56281329]\n",
      " [0.56603975]\n",
      " [0.56929576]\n",
      " [0.57258167]\n",
      " [0.57589786]\n",
      " [0.5792447 ]\n",
      " [0.58262258]\n",
      " [0.58603187]\n",
      " [0.58947297]\n",
      " [0.59294628]\n",
      " [0.59645221]\n",
      " [0.59999128]\n",
      " [0.60356393]\n",
      " [0.60717059]\n",
      " [0.61081172]\n",
      " [0.61448776]\n",
      " [0.61819916]\n",
      " [0.6219464 ]\n",
      " [0.62572995]\n",
      " [0.62955028]\n",
      " [0.63340787]\n",
      " [0.63730323]\n",
      " [0.64123684]\n",
      " [0.64520923]\n",
      " [0.6492209 ]\n",
      " [0.65327238]\n",
      " [0.65736419]\n",
      " [0.66149689]\n",
      " [0.665671  ]\n",
      " [0.6698871 ]\n",
      " [0.67414574]\n",
      " [0.67844749]\n",
      " [0.68279294]\n",
      " [0.68718267]\n",
      " [0.69161728]\n",
      " [0.69609738]\n",
      " [0.70062375]\n",
      " [0.70519709]\n",
      " [0.70981806]\n",
      " [0.71448734]\n",
      " [0.71920562]\n",
      " [0.72397361]\n",
      " [0.72879202]\n",
      " [0.73366157]\n",
      " [0.73858301]\n",
      " [0.74355709]\n",
      " [0.74858456]\n",
      " [0.7536662 ]\n",
      " [0.75880281]\n",
      " [0.76399518]\n",
      " [0.76924412]\n",
      " [0.77455048]\n",
      " [0.77991508]\n",
      " [0.78533878]\n",
      " [0.79082247]\n",
      " [0.796367  ]\n",
      " [0.80197337]\n",
      " [0.80764264]\n",
      " [0.81337578]\n",
      " [0.81917379]\n",
      " [0.82503767]\n",
      " [0.83096841]\n",
      " [0.83696708]\n",
      " [0.84303471]\n",
      " [0.84917239]\n",
      " [0.8553812 ]\n",
      " [0.86166225]\n",
      " [0.86801668]\n",
      " [0.87444563]\n",
      " [0.88095029]\n",
      " [0.88753183]\n",
      " [0.89419147]\n",
      " [0.90093045]\n",
      " [0.90775002]\n",
      " [0.91465145]\n",
      " [0.92163605]\n",
      " [0.92870514]\n",
      " [0.93586032]\n",
      " [0.94310311]\n",
      " [0.95043497]\n",
      " [0.9578574 ]\n",
      " [0.96537191]\n",
      " [0.97298006]\n",
      " [0.98068342]\n",
      " [0.98848362]\n",
      " [0.99638228]\n",
      " [1.00438109]\n",
      " [1.01248174]\n",
      " [1.02068599]\n",
      " [1.0289956 ]\n",
      " [1.03741238]\n",
      " [1.04593817]\n",
      " [1.05457485]\n",
      " [1.06332434]\n",
      " [1.07218889]\n",
      " [1.08117063]\n",
      " [1.09027167]\n",
      " [1.09949414]\n",
      " [1.10884024]\n",
      " [1.11831219]\n",
      " [1.12791229]\n",
      " [1.13764286]\n",
      " [1.14750626]\n",
      " [1.15750493]\n",
      " [1.16764134]\n",
      " [1.177918  ]\n",
      " [1.18833749]\n",
      " [1.19890243]\n",
      " [1.2096155 ]\n",
      " [1.22047942]\n",
      " [1.23149704]\n",
      " [1.24267166]\n",
      " [1.25400638]\n",
      " [1.26550431]\n",
      " [1.27716862]\n",
      " [1.28900255]\n",
      " [1.3010094 ]\n",
      " [1.31319256]\n",
      " [1.32555549]\n",
      " [1.33810172]\n",
      " [1.35083488]\n",
      " [1.36375864]\n",
      " [1.37687679]\n",
      " [1.39019318]\n",
      " [1.40371178]\n",
      " [1.41743712]\n",
      " [1.43137354]\n",
      " [1.4455254 ]\n",
      " [1.45989715]\n",
      " [1.47449336]\n",
      " [1.48931869]\n",
      " [1.50437791]\n",
      " [1.5196759 ]\n",
      " [1.53521766]\n",
      " [1.55100829]\n",
      " [1.56705301]\n",
      " [1.58335716]\n",
      " [1.5999262 ]\n",
      " [1.61676578]\n",
      " [1.63388243]\n",
      " [1.65128247]\n",
      " [1.66897213]\n",
      " [1.68695781]\n",
      " [1.70524605]\n",
      " [1.72384356]\n",
      " [1.7427572 ]\n",
      " [1.76199402]\n",
      " [1.7815612 ]\n",
      " [1.80146611]\n",
      " [1.82171631]\n",
      " [1.8423195 ]\n",
      " [1.86328358]\n",
      " [1.8846167 ]\n",
      " [1.90632813]\n",
      " [1.92842704]\n",
      " [1.95092253]\n",
      " [1.97382394]\n",
      " [1.99714083]\n",
      " [2.02088302]\n",
      " [2.04506058]\n",
      " [2.06968385]\n",
      " [2.09476339]\n",
      " [2.12031006]\n",
      " [2.14633505]\n",
      " [2.17285068]\n",
      " [2.19986911]\n",
      " [2.22740266]\n",
      " [2.25546395]\n",
      " [2.28406594]\n",
      " [2.31322191]\n",
      " [2.34294546]\n",
      " [2.37325055]\n",
      " [2.40415145]\n",
      " [2.4356628 ]\n",
      " [2.46779987]\n",
      " [2.50057968]\n",
      " [2.53401873]\n",
      " [2.56813374]\n",
      " [2.60294183]\n",
      " [2.63846058]\n",
      " [2.67470797]\n",
      " [2.71170241]\n",
      " [2.74946277]\n",
      " [2.78800832]\n",
      " [2.82735876]\n",
      " [2.86753477]\n",
      " [2.90855894]\n",
      " [2.95045326]\n",
      " [2.99324014]\n",
      " [3.03694249]\n",
      " [3.08158376]\n",
      " [3.12718792]\n",
      " [3.17377943]\n",
      " [3.22138323]\n",
      " [3.27002541]\n",
      " [3.31973331]\n",
      " [3.37053393]\n",
      " [3.42245481]\n",
      " [3.47552395]\n",
      " [3.52976981]\n",
      " [3.58522129]\n",
      " [3.64190767]\n",
      " [3.69985858]\n",
      " [3.75910526]\n",
      " [3.81967944]\n",
      " [3.88161242]\n",
      " [3.94493568]\n",
      " [4.00968092]\n",
      " [4.07587988]\n",
      " [4.14356434]\n",
      " [4.21276593]\n",
      " [4.28351617]\n",
      " [4.35584708]\n",
      " [4.42979005]\n",
      " [4.50537562]\n",
      " [4.58263359]\n",
      " [4.66159288]\n",
      " [4.74228128]\n",
      " [4.82472529]\n",
      " [4.90894983]\n",
      " [4.99497772]\n",
      " [5.08282779]\n",
      " [5.17251739]\n",
      " [5.26406127]\n",
      " [5.35747101]\n",
      " [5.45275451]\n",
      " [5.54991564]\n",
      " [5.6489537 ]\n",
      " [5.74986299]\n",
      " [5.85263046]\n",
      " [5.95723104]\n",
      " [6.06363574]\n",
      " [6.17180798]\n",
      " [6.28170247]\n",
      " [6.39326453]\n",
      " [6.50642676]\n",
      " [6.62110552]\n",
      " [6.73720878]\n",
      " [6.85463164]\n",
      " [6.97325543]\n",
      " [7.09294691]\n",
      " [7.21355246]\n",
      " [7.33489525]\n",
      " [7.45678506]\n",
      " [7.57901323]\n",
      " [7.70135111]\n",
      " [7.82354514]\n",
      " [7.94532404]\n",
      " [8.06639718]\n",
      " [8.18645413]\n",
      " [8.30515845]\n",
      " [8.42215473]\n",
      " [8.53707213]\n",
      " [8.64952366]\n",
      " [8.75910524]\n",
      " [8.86539672]\n",
      " [8.96797168]\n",
      " [9.06639755]\n",
      " [9.16023866]\n",
      " [9.24905795]\n",
      " [9.33242529]\n",
      " [9.40992119]\n",
      " [9.48114133]\n",
      " [9.54570222]\n",
      " [9.60324546]\n",
      " [9.65344257]\n",
      " [9.69600009]\n",
      " [9.7306652 ]\n",
      " [9.75722944]\n",
      " [9.77552947]\n",
      " [9.78545163]\n",
      " [9.78693453]\n",
      " [9.77996951]\n",
      " [9.76459982]\n",
      " [9.7409208 ]\n",
      " [9.7090776 ]\n",
      " [9.66926317]\n",
      " [9.62171648]\n",
      " [9.56671697]\n",
      " [9.50457963]\n",
      " [9.43565344]\n",
      " [9.3603148 ]\n",
      " [9.2789601 ]\n",
      " [9.19200451]\n",
      " [9.09987592]\n",
      " [9.00300764]\n",
      " [8.90183639]\n",
      " [8.79679785]\n",
      " [8.68832175]\n",
      " [8.57682896]\n",
      " [8.46272853]\n",
      " [8.34641496]\n",
      " [8.22826745]\n",
      " [8.10864622]\n",
      " [7.98789109]\n",
      " [7.86632156]\n",
      " [7.74423975]\n",
      " [7.62192419]\n",
      " [7.49963089]\n",
      " [7.37759609]\n",
      " [7.25603939]\n",
      " [7.13515714]\n",
      " [7.01512302]\n",
      " [6.89610364]\n",
      " [6.77823869]\n",
      " [6.66165469]\n",
      " [6.54646116]\n",
      " [6.43275635]\n",
      " [6.320625  ]\n",
      " [6.21013772]\n",
      " [6.10135385]\n",
      " [5.99432266]\n",
      " [5.88908377]\n",
      " [5.78566656]\n",
      " [5.68409453]\n",
      " [5.5843852 ]\n",
      " [5.48655096]\n",
      " [5.39059988]\n",
      " [5.29652879]\n",
      " [5.20432922]\n",
      " [5.11399053]\n",
      " [5.02549812]\n",
      " [4.93883433]\n",
      " [4.85398029]\n",
      " [4.77091422]\n",
      " [4.68961253]\n",
      " [4.61005024]\n",
      " [4.53219986]\n",
      " [4.45603221]\n",
      " [4.38151777]\n",
      " [4.30862628]\n",
      " [4.23732691]\n",
      " [4.16758802]\n",
      " [4.09937784]\n",
      " [4.03266447]\n",
      " [3.96741601]\n",
      " [3.9036005 ]\n",
      " [3.84118593]\n",
      " [3.78014067]\n",
      " [3.72043338]\n",
      " [3.66203303]\n",
      " [3.6049089 ]\n",
      " [3.54903061]\n",
      " [3.49436834]\n",
      " [3.44089277]\n",
      " [3.38857498]\n",
      " [3.3373864 ]\n",
      " [3.28729925]\n",
      " [3.23828632]\n",
      " [3.19032106]\n",
      " [3.14337751]\n",
      " [3.09743034]\n",
      " [3.05245488]\n",
      " [3.00842711]\n",
      " [2.96532324]\n",
      " [2.92311914]\n",
      " [2.88179213]\n",
      " [2.84132023]\n",
      " [2.80168209]\n",
      " [2.76285694]\n",
      " [2.72482464]\n",
      " [2.68756564]\n",
      " [2.65106101]\n",
      " [2.61529207]\n",
      " [2.58023931]\n",
      " [2.54588474]\n",
      " [2.51221104]\n",
      " [2.47920143]\n",
      " [2.44683964]\n",
      " [2.4151099 ]\n",
      " [2.38399693]\n",
      " [2.35348595]\n",
      " [2.32356249]\n",
      " [2.29421131]\n",
      " [2.26541827]\n",
      " [2.23716988]\n",
      " [2.20945306]\n",
      " [2.18225515]\n",
      " [2.15556385]\n",
      " [2.12936728]\n",
      " [2.10365393]\n",
      " [2.07841474]\n",
      " [2.05363267]\n",
      " [2.02930015]\n",
      " [2.00540653]\n",
      " [1.98194155]\n",
      " [1.95889525]\n",
      " [1.93625802]\n",
      " [1.91402054]\n",
      " [1.89217383]\n",
      " [1.87070916]\n",
      " [1.84961759]\n",
      " [1.82889049]\n",
      " [1.80851966]\n",
      " [1.78849713]\n",
      " [1.76881512]\n",
      " [1.74946606]\n",
      " [1.73044254]\n",
      " [1.71173736]\n",
      " [1.69334344]\n",
      " [1.67525388]\n",
      " [1.65746221]\n",
      " [1.63996222]\n",
      " [1.62274763]\n",
      " [1.6058123 ]\n",
      " [1.58915023]\n",
      " [1.57275556]\n",
      " [1.55662253]\n",
      " [1.54074553]\n",
      " [1.52511903]\n",
      " [1.50973763]\n",
      " [1.49459628]\n",
      " [1.47969039]\n",
      " [1.46501513]\n",
      " [1.45056577]\n",
      " [1.43633769]\n",
      " [1.4223264 ]\n",
      " [1.40852749]\n",
      " [1.39493667]\n",
      " [1.38154975]\n",
      " [1.36836262]\n",
      " [1.35537132]\n",
      " [1.34257205]\n",
      " [1.32996105]\n",
      " [1.31753463]\n",
      " [1.30528918]\n",
      " [1.29322118]\n",
      " [1.28132721]\n",
      " [1.2696039 ]\n",
      " [1.25804796]\n",
      " [1.24665619]\n",
      " [1.23542545]\n",
      " [1.22435276]\n",
      " [1.21343515]\n",
      " [1.20266971]\n",
      " [1.19205361]\n",
      " [1.18158407]\n",
      " [1.17125838]\n",
      " [1.16107388]\n",
      " [1.15102798]\n",
      " [1.14111814]\n",
      " [1.13134188]\n",
      " [1.1216968 ]\n",
      " [1.11218056]\n",
      " [1.10279085]\n",
      " [1.09352542]\n",
      " [1.08438205]\n",
      " [1.07535858]\n",
      " [1.06645289]\n",
      " [1.05766291]\n",
      " [1.04898662]\n",
      " [1.04042203]\n",
      " [1.03196724]\n",
      " [1.02362037]\n",
      " [1.01537958]\n",
      " [1.00724306]\n",
      " [0.99920902]\n",
      " [0.99127572]\n",
      " [0.98344147]\n",
      " [0.97570459]\n",
      " [0.96806344]\n",
      " [0.96051641]\n",
      " [0.95306193]\n",
      " [0.94569846]\n",
      " [0.93842447]\n",
      " [0.93123848]\n",
      " [0.92413902]\n",
      " [0.91712473]\n",
      " [0.91019429]\n",
      " [0.90334635]\n",
      " [0.8965796 ]\n",
      " [0.88989272]\n",
      " [0.88328444]\n",
      " [0.87675352]\n",
      " [0.87029873]\n",
      " [0.86391886]\n",
      " [0.85761274]\n",
      " [0.85137919]\n",
      " [0.8452171 ]\n",
      " [0.83912533]\n",
      " [0.83310278]\n",
      " [0.82714839]\n",
      " [0.82126111]\n",
      " [0.81543997]\n",
      " [0.80968396]\n",
      " [0.80399211]\n",
      " [0.79836344]\n",
      " [0.79279701]\n",
      " [0.78729188]\n",
      " [0.78184713]\n",
      " [0.77646187]\n",
      " [0.77113522]\n",
      " [0.76586629]\n",
      " [0.76065425]\n",
      " [0.75549824]\n",
      " [0.75039745]\n",
      " [0.74535107]\n",
      " [0.74035831]\n",
      " [0.73541842]\n",
      " [0.73053065]\n",
      " [0.72569427]\n",
      " [0.72090853]\n",
      " [0.71617271]\n",
      " [0.71148612]\n",
      " [0.70684805]\n",
      " [0.70225781]\n",
      " [0.69771475]\n",
      " [0.6932182 ]\n",
      " [0.6887675 ]\n",
      " [0.68436202]\n",
      " [0.68000113]\n",
      " [0.67568422]\n",
      " [0.67141067]\n",
      " [0.66717991]\n",
      " [0.66299137]\n",
      " [0.65884447]\n",
      " [0.65473866]\n",
      " [0.65067338]\n",
      " [0.64664809]\n",
      " [0.64266225]\n",
      " [0.63871533]\n",
      " [0.63480682]\n",
      " [0.63093621]\n",
      " [0.62710299]\n",
      " [0.62330667]\n",
      " [0.61954677]\n",
      " [0.61582281]\n",
      " [0.61213432]\n",
      " [0.60848084]\n",
      " [0.60486193]\n",
      " [0.60127715]\n",
      " [0.59772607]\n",
      " [0.59420824]\n",
      " [0.59072324]\n",
      " [0.58727066]\n",
      " [0.58385009]\n",
      " [0.58046112]\n",
      " [0.57710335]\n",
      " [0.5737764 ]\n",
      " [0.57047987]\n",
      " [0.56721338]\n",
      " [0.56397656]\n",
      " [0.56076904]\n",
      " [0.55759047]\n",
      " [0.5544405 ]\n",
      " [0.55131879]\n",
      " [0.54822498]\n",
      " [0.54515874]\n",
      " [0.54211974]\n",
      " [0.53910765]\n",
      " [0.53612213]\n",
      " [0.53316287]\n",
      " [0.53022956]\n",
      " [0.52732188]\n",
      " [0.52443953]\n",
      " [0.5215822 ]\n",
      " [0.5187496 ]\n",
      " [0.51594143]\n",
      " [0.5131574 ]\n",
      " [0.51039722]\n",
      " [0.50766062]\n",
      " [0.50494731]\n",
      " [0.50225701]\n",
      " [0.49958946]\n",
      " [0.49694439]\n",
      " [0.49432154]\n",
      " [0.49172069]\n",
      " [0.48914159]\n",
      " [0.48658399]\n",
      " [0.48404765]\n",
      " [0.48153233]\n",
      " [0.47903778]\n",
      " [0.47656378]\n",
      " [0.4741101 ]\n",
      " [0.4716765 ]\n",
      " [0.46926276]\n",
      " [0.46686865]\n",
      " [0.46449397]\n",
      " [0.4621385 ]\n",
      " [0.45980201]\n",
      " [0.4574843 ]\n",
      " [0.45518517]\n",
      " [0.4529044 ]\n",
      " [0.4506418 ]\n",
      " [0.44839716]\n",
      " [0.44617028]\n",
      " [0.44396098]\n",
      " [0.44176906]\n",
      " [0.43959436]\n",
      " [0.43743668]\n",
      " [0.43529585]\n",
      " [0.43317169]\n",
      " [0.43106403]\n",
      " [0.42897268]\n",
      " [0.42689748]\n",
      " [0.42483825]\n",
      " [0.42279482]\n",
      " [0.42076704]\n",
      " [0.41875473]\n",
      " [0.41675774]\n",
      " [0.4147759 ]\n",
      " [0.41280906]\n",
      " [0.41085706]\n",
      " [0.40891975]\n",
      " [0.40699697]\n",
      " [0.40508857]\n",
      " [0.40319441]\n",
      " [0.40131434]\n",
      " [0.39944821]\n",
      " [0.39759588]\n",
      " [0.39575722]\n",
      " [0.3939321 ]\n",
      " [0.39212038]\n",
      " [0.39032192]\n",
      " [0.3885366 ]\n",
      " [0.38676428]\n",
      " [0.38500484]\n",
      " [0.38325814]\n",
      " [0.38152405]\n",
      " [0.37980246]\n",
      " [0.37809324]\n",
      " [0.37639627]\n",
      " [0.37471143]\n",
      " [0.3730386 ]\n",
      " [0.37137766]\n",
      " [0.36972849]\n",
      " [0.36809099]\n",
      " [0.36646503]\n",
      " [0.36485051]\n",
      " [0.36324731]\n",
      " [0.36165532]\n",
      " [0.36007444]\n",
      " [0.35850456]\n",
      " [0.35694559]\n",
      " [0.35539742]\n",
      " [0.35385994]\n",
      " [0.35233306]\n",
      " [0.35081667]\n",
      " [0.34931069]\n",
      " [0.347815  ]\n",
      " [0.34632952]\n",
      " [0.34485414]\n",
      " [0.34338878]\n",
      " [0.34193334]\n",
      " [0.34048773]\n",
      " [0.33905186]\n",
      " [0.33762563]\n",
      " [0.33620896]\n",
      " [0.33480177]\n",
      " [0.33340395]\n",
      " [0.33201544]]\n",
      "[Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True)]\n",
      "Stopping search: Swarm best objective change less than 1e-08\n",
      "pso Optimized parameters: [ 8.90831458  4.45502381  5.15117291  9.78741761  6.19261896  8.73090737\n",
      "  5.5220978   0.20807064 -0.92205301  0.39942051]\n",
      "pso Optimized loss: 1.190352831070742e-10\n",
      "[ 8.90831458  4.45502381  5.15117291  9.78741761  6.19261896  8.73090737\n",
      "  5.5220978   0.20807064 -0.92205301  0.39942051]\n",
      "最终损失值 (MSE): -1.190352831070742e-10\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "import pandas as pd\n",
    "# 读取 CSV 文件并转换为 NumPy 数组\n",
    "data0 = pd.read_csv('./relative_particle/relative_particle.csv')#\n",
    "tae = data0.to_numpy()\n",
    "\n",
    "# 使用 JAX 的数组操作替换 PyTorch 的操作\n",
    "state = jnp.array(tae[:, :2], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "true_q_ddot = jnp.array(tae[:, 3:], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "print(state.shape)\n",
    "print(true_q_ddot)\n",
    "# 将数据存储在字典中\n",
    "data = {\n",
    "    'inputs': state,\n",
    "    'outputs': true_q_ddot,  # 真实的加速度\n",
    "}\n",
    "\n",
    "'''inputs, outputs = data['inputs'], data['outputs']\n",
    "n_dim = inputs.shape[1] // 2\n",
    "q = inputs[:, :n_dim]\n",
    "q_t = inputs[:, n_dim:]\n",
    "true_accelerations = outputs\n",
    "\n",
    "initial_params = jnp.array([1.0, 1.0, 1.0, 9.787379841057392 ], dtype=jnp.float64)  # 初始参数\n",
    "\n",
    "print(equation(q,q_t,initial_params))'''\n",
    "\n",
    "print(initial_params)\n",
    "# 评估并优化参数\n",
    "final_loss = evaluate(data, initial_params)\n",
    "print(\"最终损失值 (MSE):\", final_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568969d",
   "metadata": {},
   "source": [
    "# 检验.sum是否影响求解梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "# 定义方程\n",
    "def equation(q: jnp.array, q_t: jnp.array, params: jnp.array):\n",
    "    T = 1 / jnp.sqrt(1 - q_t**2) - params[1]\n",
    "    V = -params[3] * q   \n",
    "    result = T - V\n",
    "    return result\n",
    "\n",
    "# 示例数据\n",
    "key = jax.random.PRNGKey(0)\n",
    "q = jax.random.uniform(key, (100,), minval=-0.5, maxval=0.5)  # 随机 q\n",
    "q_t = jax.random.uniform(key, (100,), minval=-0.9, maxval=0.9)  # 随机 q_t，|q_t| < 1\n",
    "params = jnp.array([0.0, 1.0, 0.0, 2.0])  # 示例参数，params[1] = 1.0, params[3] = 2.0\n",
    "\n",
    "# 方式 1：分别计算每个数据点的梯度\n",
    "def single_point_grad(q_i, q_t_i, params):\n",
    "    # 计算单个数据点的梯度\n",
    "    grad_fn = jax.grad(equation, argnums=(0, 1))\n",
    "    grad_q, grad_q_t = grad_fn(q_i, q_t_i, params)\n",
    "    return grad_q, grad_q_t\n",
    "\n",
    "# 使用 vmap 向量化处理 100 个数据点\n",
    "vectorized_grad = jax.vmap(single_point_grad, in_axes=(0, 0, None))\n",
    "grad_q_1, grad_q_t_1 = vectorized_grad(q, q_t, params)\n",
    "\n",
    "# 方式 2：对输出求和后再计算梯度\n",
    "def summed_equation(q, q_t, params):\n",
    "    return equation(q, q_t, params).sum()\n",
    "\n",
    "grad_fn_sum = jax.grad(summed_equation, argnums=(0, 1))\n",
    "grad_q_2, grad_q_t_2 = grad_fn_sum(q, q_t, params)\n",
    "\n",
    "# 比较两种方式的结果\n",
    "print(\"关于 q 的梯度（方式 1）：\", grad_q_1[:5])  # 打印前 5 个\n",
    "print(\"关于 q 的梯度（方式 2）：\", grad_q_2[:5])\n",
    "print(\"关于 q 的梯度差异：\", jnp.abs(grad_q_1 - grad_q_2).max())\n",
    "\n",
    "print(\"关于 q_t 的梯度（方式 1）：\", grad_q_t_1[:5])\n",
    "print(\"关于 q_t 的梯度（方式 2）：\", grad_q_t_2[:5])\n",
    "print(\"关于 q_t 的梯度差异：\", jnp.abs(grad_q_t_1 - grad_q_t_2).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98923f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = jnp.power(2,-2.5)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a67f9",
   "metadata": {},
   "source": [
    "# 检查完毕代码的数据结构，开始撰写SPECIFICATION文档供LLM-SR模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the mathematical function skeleton that represents lagrangian in a physical system, given data on generalized coordinate and generalized velocity.\n",
    "Tips:You may only use no more than 10 parameters,Under limited parameter conditions, you can incorporate nonlinear terms rather than continuously adding new ones.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import config, jit, vmap\n",
    "from pyswarm import pso\n",
    "from jax.scipy.optimize import minimize\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "MAX_NPARAMS = 10\n",
    "initial_params = [jnp.array(1.0)]*MAX_NPARAMS\n",
    "\n",
    "@evaluate.run\n",
    "def evaluate(data: dict, params=initial_params) -> float:\n",
    "\n",
    "    inputs, outputs = data['inputs'], data['outputs']\n",
    "    n_dim = inputs.shape[1] // 2\n",
    "    q = inputs[:, :n_dim]\n",
    "    q_t = inputs[:, n_dim:]\n",
    "    true_accelerations = outputs\n",
    "\n",
    "\n",
    "    # 修改：将lagrangian直接嵌入compute_acceleration中，避免将函数作为参数传递\n",
    "    @jit\n",
    "    def compute_acceleration(q, q_t, params):\n",
    "        # 直接使用equation函数而不是传递lagrangian函数\n",
    "        \n",
    "        # 预先计算梯度\n",
    "        @jit\n",
    "        def lag(q_single, q_t_single, params):\n",
    "            # 确保对单个样本调用时返回标量\n",
    "            result = equation(q_single, q_t_single, params)\n",
    "            # 如果结果是数组，取和或平均值来确保返回标量\n",
    "            return result\n",
    "            \n",
    "        # 计算二阶导数\n",
    "        hessian_q_t = jax.hessian(lag, 1)(q, q_t, params)\n",
    "        grad_q = jax.grad(lag, 0)(q, q_t, params)\n",
    "        jacobian_q_q_t = jax.jacobian(jax.grad(lag, 1), 0)(q, q_t, params)\n",
    "        q_tt = jnp.linalg.pinv(hessian_q_t) @ (grad_q - jacobian_q_q_t @ q_t)\n",
    "        return q_tt\n",
    "\n",
    "    # 使用vmap批处理\n",
    "    batch_compute_acceleration = jit(vmap(compute_acceleration, in_axes=(0, 0, None)))\n",
    "\n",
    "    # 使用jit装饰器优化损失函数\n",
    "    @jit\n",
    "    def loss_fn(params):\n",
    "        predicted_accelerations = batch_compute_acceleration(q, q_t, params)\n",
    "        return jnp.mean(jnp.square(predicted_accelerations - true_accelerations))\n",
    "    \n",
    "    #return loss_fn(params)\n",
    "\n",
    "    # 针对numpy数组的包装函数\n",
    "    def objective(params):\n",
    "        try:\n",
    "            params = jnp.array(params)  # 确保转换为JAX数组\n",
    "            loss_value = loss_fn(params)\n",
    "            return float(loss_value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in objective function: {e}\")\n",
    "            # 返回一个大的损失值，避免优化器选择这个点\n",
    "            return 1e10\n",
    "\n",
    "    # 粒子群优化的参数\n",
    "    lb = [-10.0] * len(initial_params)  # 参数下限\n",
    "    ub = [10.0] * len(initial_params)   # 参数上限\n",
    "\n",
    "    # 调用 pso 函数进行优化\n",
    "    optimized_params, optimized_loss = pso(objective, lb, ub, swarmsize=30, maxiter=500)\n",
    "\n",
    "    print(\"pso Optimized parameters:\", optimized_params)\n",
    "    print(\"pso Optimized loss:\", optimized_loss)\n",
    "\n",
    "    # 使用JAX的优化器进一步优化\n",
    "    loss_partial = jit(loss_fn)  # 确保JIT编译\n",
    "    result = minimize(loss_partial, optimized_params, method='BFGS', options={'maxiter': 1000})\n",
    "    optimized_params = result.x\n",
    "    loss = result.fun\n",
    "\n",
    "    if jnp.isnan(loss) or jnp.isinf(loss):\n",
    "        return None\n",
    "    else:\n",
    "        print(optimized_params)\n",
    "        return -loss.item()\n",
    "\n",
    "@equation.evolve\n",
    "@jit\n",
    "def equation(q: jnp.array, q_t: jnp.array, params: jnp.array):\n",
    "    \"\"\" Mathematical function for lagrangian in a one-dimensional physical system\n",
    "    Args:\n",
    "        q (jnp.array): observation of current generalized coordinate.\n",
    "        q_t (jnp.array): observation of generalized velocity.\n",
    "        params (jnp.array): List of numeric constants or parameters to be optimized.\n",
    "    Returns:\n",
    "        jnp.array: lagrangian as the result of applying the mathematical function to the inputs.\n",
    "    \"\"\" \n",
    "    q = q[...,0]\n",
    "    q_t = q_t[...,0]\n",
    "    T = params[0]*jnp.power(1-q_t**2,-1)+params[1] + params[2]*jnp.power(q_t,2) - params[4]\n",
    "    V = -params[3]*q + params[5]   \n",
    "    \n",
    "    result = T - V\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98a7e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "[Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True), Array(1., dtype=float64, weak_type=True)]\n",
      "Stopping search: Swarm best objective change less than 1e-08\n",
      "pso Optimized parameters: [0.25336819 8.11832287 0.15681473 7.84612288 7.27479332 1.46364404\n",
      " 9.3834202  3.20691351 1.65209292 3.38102884]\n",
      "pso Optimized loss: 0.010096556562511948\n",
      "[0.25338648 8.11832287 0.15680736 7.84612243 7.27479332 1.46364404\n",
      " 9.3834202  3.20691351 1.65209292 3.38102884]\n",
      "最终损失值 (MSE): -0.0100965436749942\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "import pandas as pd\n",
    "# 读取 CSV 文件并转换为 NumPy 数组\n",
    "data0 = pd.read_csv('./relative_particle/relative_particle.csv')#\n",
    "tae = data0.to_numpy()\n",
    "\n",
    "# 使用 JAX 的数组操作替换 PyTorch 的操作\n",
    "state = jnp.array(tae[:, :2], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "g = jnp.array(tae[:, 2:3], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "true_q_ddot = jnp.array(tae[:, 3:], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "print(state.shape)\n",
    "#print(g)\n",
    "#print(true_q_ddot)\n",
    "# 将数据存储在字典中\n",
    "data = {\n",
    "    'inputs': state,\n",
    "    'outputs': true_q_ddot,\n",
    "    'condition': g  # 真实的加速度\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print(initial_params)\n",
    "# 评估并优化参数\n",
    "final_loss = evaluate(data, initial_params)\n",
    "print(\"最终损失值 (MSE):\", final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffada5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
