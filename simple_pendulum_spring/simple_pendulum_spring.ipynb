{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bfb7ff",
   "metadata": {},
   "source": [
    "## 生成哈密顿量的txt文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64daed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the mathematical function skeleton that represents acceleration in a system, given data on time, position, and velocity.\n",
    "A large positive sensitivity value for param[i] means that removing it significantly hurts the function's performance,\n",
    "You should select those formulas with high sensitivity of parameter and remove formulas with low sensitivity of parameter, then add one or two new formula.\n",
    "\"\"\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import config, grad, jit, vmap\n",
    "from pyswarm import pso\n",
    "from jax.scipy.optimize import minimize\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "MAX_NPARAMS = 10\n",
    "initial_params = jnp.ones(MAX_NPARAMS, dtype=jnp.float64)\n",
    "\n",
    "#@evaluate.run\n",
    "def evaluate(data: dict, params=initial_params) -> dict:\n",
    "    inputs, outputs = data['inputs'], data['outputs']\n",
    "    n_dim = inputs.shape[1] // 2\n",
    "    q, p = inputs[:, :n_dim], inputs[:, n_dim:]\n",
    "    true_value = outputs\n",
    "    \n",
    "    @jit\n",
    "    def compute_dynamics(q, p, params):\n",
    "        def hamiltonian(q, p, params):\n",
    "            return equation(q, p, params)  \n",
    "        q_dot = jax.grad(hamiltonian, 1)(q, p, params)  \n",
    "        p_dot = -jax.grad(hamiltonian, 0)(q, p, params)  \n",
    "        return jnp.concatenate([q_dot, p_dot])\n",
    "\n",
    "    batch_compute_dynamics = jit(vmap(compute_dynamics, (0, 0, None)))\n",
    "\n",
    "    @jit\n",
    "    def loss_fn(params):\n",
    "        pred = batch_compute_dynamics(q, p, params)\n",
    "        return jnp.mean(jnp.square(pred - true_value))\n",
    "\n",
    "    def run_optimization(objective_fn, initial_guess):\n",
    "        if initial_guess.size > MAX_NPARAMS:\n",
    "            result = minimize(objective_fn, initial_guess,\n",
    "                            method='BFGS', options={'maxiter': 500})\n",
    "            return result.x\n",
    "        else:\n",
    "            def pso_wrapper(x):\n",
    "                return objective_fn(jnp.array(x))   \n",
    "\n",
    "            lb = [-10.0]*initial_guess.size\n",
    "            ub = [10.0]*initial_guess.size\n",
    "            pso_params, _ = pso(pso_wrapper, lb, ub, \n",
    "                            swarmsize=100, maxiter=300,omega=0.729, phip=1.49445, phig=1.49445)\n",
    "            \n",
    "            result = minimize(objective_fn, jnp.array(pso_params),\n",
    "                            method='BFGS', options={'maxiter': 500})\n",
    "            return result.x\n",
    "\n",
    "    def calculate_sensitivities(opt_params, base_loss):\n",
    "        mask = 1 - jnp.eye(MAX_NPARAMS)\n",
    "        \n",
    "        @jit      \n",
    "        def batch_loss(params_matrix):\n",
    "            return vmap(loss_fn)(params_matrix * mask)\n",
    "\n",
    "        def sensitivity_objective(flat_params):\n",
    "            matrix_params = flat_params.reshape(MAX_NPARAMS, MAX_NPARAMS)\n",
    "            return jnp.sum(batch_loss(matrix_params))\n",
    "\n",
    "        try:\n",
    "            initial_flat = (opt_params * mask).flatten()\n",
    "            optimized_flat = run_optimization(sensitivity_objective, initial_flat)\n",
    "            optimized_matrix = optimized_flat.reshape(MAX_NPARAMS, MAX_NPARAMS)\n",
    "            losses = batch_loss(optimized_matrix)\n",
    "            relative_loss = jnp.log2(losses / base_loss)\n",
    "            return jnp.round(relative_loss,4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Sensitivity analysis error: {str(e)}\")\n",
    "            return jnp.zeros(MAX_NPARAMS, dtype=jnp.float64)\n",
    "\n",
    "    try:\n",
    "        optimized_params = run_optimization(loss_fn, params)\n",
    "        final_loss = loss_fn(optimized_params)\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not jnp.isfinite(final_loss):\n",
    "        return None\n",
    "\n",
    "    sensitivities = calculate_sensitivities(optimized_params, final_loss)\n",
    "    sensitivity_dict = {f\"sensitive of params[{i}]\": float(sensitivities[i])\n",
    "                       for i in range(len(sensitivities))}\n",
    "\n",
    "    return {\n",
    "        'params': optimized_params,\n",
    "        'loss': -final_loss.item(),\n",
    "        'sensitivities': sensitivity_dict\n",
    "    }\n",
    "\n",
    "#@equation.evolve\n",
    "@jit\n",
    "def equation(q: jnp.array, p: jnp.array, params: jnp.array) -> jnp.array:\n",
    "    q = q[...,0]\n",
    "    p = p[...,0]\n",
    "     \n",
    "    #T = params[1] * jnp.square(p)\n",
    "    #V =  params[3] * jnp.square(q) +params[0]*q +params[2]\n",
    "\n",
    "    T = params[1] * jnp.square(p) \n",
    "    V = params[3] * jnp.cos(params[2]*q)+params[0]\n",
    "\n",
    "    return T + V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "393aa9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -4.15778787e+01]\n",
      " [-8.66419284e-03 -4.15774283e+01]\n",
      " [-1.73281980e-02 -4.15760771e+01]\n",
      " ...\n",
      " [-1.08776333e+00  3.30105593e+01]\n",
      " [-1.08087271e+00  3.31423153e+01]\n",
      " [-1.07395339e+00  3.32730311e+01]]\n",
      "[[  0.78539816   0.        ]\n",
      " [  0.78538733  -0.10397031]\n",
      " [  0.78535483  -0.20793838]\n",
      " ...\n",
      " [ -0.5960815  -13.05316   ]\n",
      " [ -0.59879171 -12.97047246]\n",
      " [ -0.60148549 -12.8874407 ]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Initial guess size: 10, MAX_NPARAMS: 10\n",
      "Running pyswarms PSO 5 times with unique initial swarms...\n",
      "  PSO Run 1/5 (using JAX key split for init_pos)\n",
      "    Run 1 completed. Loss: 47.716996918889336\n",
      "    New best PSO loss found: 47.716996918889336\n",
      "  PSO Run 2/5 (using JAX key split for init_pos)\n",
      "    Run 2 completed. Loss: 47.46092602477515\n",
      "    New best PSO loss found: 47.46092602477515\n",
      "  PSO Run 3/5 (using JAX key split for init_pos)\n",
      "    Run 3 completed. Loss: 47.899002086546666\n",
      "  PSO Run 4/5 (using JAX key split for init_pos)\n",
      "    Run 4 completed. Loss: 47.50131440696313\n",
      "  PSO Run 5/5 (using JAX key split for init_pos)\n",
      "    Run 5 completed. Loss: 47.61648873474167\n",
      "\n",
      "Best PSO loss after 5 runs: 47.46092602477515\n",
      "Refining best PSO result with BFGS...\n",
      "BFGS refinement successful. Final loss: 9.100385351222603e-11\n",
      "Final optimized loss: 9.100385351222603e-11\n",
      "Initial guess size: 100, MAX_NPARAMS: 10\n",
      "Using BFGS directly due to large number of parameters.\n",
      "最终损失值 (MSE): {'params': array([ 1.48935415e+00,  4.16666587e-02, -1.00000800e+00, -5.87991322e+01,\n",
      "        1.44529331e+00,  4.93488244e+00, -6.02747796e+00,  1.44256879e+00,\n",
      "        6.87854386e-01,  4.43927388e+00]), 'loss': Array(9.10038535e-11, dtype=float64), 'sensitivities': {'sensitive of params[0]': 0.0, 'sensitive of params[1]': 32.8821, 'sensitive of params[2]': 42.168, 'sensitive of params[3]': 42.168, 'sensitive of params[4]': 0.0, 'sensitive of params[5]': 0.0, 'sensitive of params[6]': 0.0, 'sensitive of params[7]': 0.0, 'sensitive of params[8]': 0.0, 'sensitive of params[9]': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 读取 CSV 文件并转换为 NumPy 数组\n",
    "data0 = pd.read_csv('./pendulum_hamilton_data.csv')\n",
    "#data0 = pd.read_csv('./hamiltonian_spring_mass_energy_data.csv')\n",
    "tae = data0.to_numpy()\n",
    "\n",
    "# 使用 JAX 的数组操作替换 PyTorch 的操作\n",
    "state = jnp.array(tae[:, 0:2], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "true_q_ddot = jnp.array(tae[:, 2:-1], dtype=jnp.float64)  # 转换为 JAX 数组\n",
    "energy = jnp.array(tae[:, -1], dtype=jnp.float64)\n",
    "print(true_q_ddot)\n",
    "print(state)\n",
    "# 将数据存储在字典中\n",
    "data = {\n",
    "    'inputs': state,\n",
    "    'outputs': true_q_ddot,  # 真实的加速度\n",
    "    'energy': energy\n",
    "}\n",
    "\n",
    "\n",
    "print(initial_params)\n",
    "# 评估并优化参数\n",
    "final_loss = evaluate(data, initial_params)\n",
    "print(\"最终损失值 (MSE):\", final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60e3ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the mathematical function skeleton that represents acceleration in a damped nonlinear oscillator system with driving force, given data on time, position, and velocity. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap, config\n",
    "from scipy.optimize import minimize\n",
    "import pyswarms as ps\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "import numpy as np\n",
    "import jax.random as random\n",
    "\n",
    "MAX_NPARAMS = 10\n",
    "initial_params = jnp.ones(MAX_NPARAMS, dtype=jnp.float64)\n",
    "\n",
    "\n",
    "def evaluate(data: dict, params=initial_params) -> dict:\n",
    "\n",
    "    master_key = random.PRNGKey(0)\n",
    "    inputs, outputs = data['inputs'], data['outputs']\n",
    "    n_dim = inputs.shape[1] // 2\n",
    "    q, p = inputs[:, :n_dim], inputs[:, n_dim:]\n",
    "    true_value = outputs\n",
    "    \n",
    "    @jit\n",
    "    def compute_dynamics(q, p, params):\n",
    "        def hamiltonian(q, p, params):\n",
    "            return equation(q, p, params)  \n",
    "        q_dot = jax.grad(hamiltonian, 1)(q, p, params)  \n",
    "        p_dot = -jax.grad(hamiltonian, 0)(q, p, params)  \n",
    "        return jnp.concatenate([q_dot, p_dot])\n",
    "\n",
    "    batch_compute_dynamics = jit(vmap(compute_dynamics, (0, 0, None)))\n",
    "\n",
    "    @jit\n",
    "    def loss_fn(params):\n",
    "        pred = batch_compute_dynamics(q, p, params)\n",
    "        return jnp.mean(jnp.square(pred - true_value))\n",
    "\n",
    "    def run_optimization(objective_fn, initial_guess, key, num_pso_runs=5, pso_iters=300, swarmsize=100):\n",
    "        print(f\"Initial guess size: {initial_guess.size}, MAX_NPARAMS: {MAX_NPARAMS}\")\n",
    "        n_params = initial_guess.size\n",
    "\n",
    "        if n_params > MAX_NPARAMS:\n",
    "            # ... (BFGS only part remains the same) ...\n",
    "            print(\"Using BFGS directly due to large number of parameters.\")\n",
    "            result = minimize(objective_fn, initial_guess,\n",
    "                              method='BFGS', options={'maxiter': 500})\n",
    "            if not result.success:\n",
    "                print(f\"BFGS optimization failed: {result.message}\")\n",
    "                return initial_guess # Fallback\n",
    "            return result.x\n",
    "        else:\n",
    "            # --- Use pyswarms with JAX-controlled initial positions ---\n",
    "            @jit\n",
    "            def pso_objective_wrapper(particles_matrix):\n",
    "                return vmap(objective_fn)(particles_matrix)\n",
    "\n",
    "            min_bound_np = np.full(n_params, -10.0, dtype=np.float64)\n",
    "            max_bound_np = np.full(n_params, 10.0, dtype=np.float64)\n",
    "            bounds = (min_bound_np, max_bound_np)\n",
    "\n",
    "            options = {'c1': 1.49445, 'c2': 1.49445, 'w': 0.729}\n",
    "\n",
    "            best_pso_params = None\n",
    "            best_pso_loss = jnp.inf\n",
    "\n",
    "            current_key = key # Use the passed-in key\n",
    "\n",
    "            print(f\"Running pyswarms PSO {num_pso_runs} times with unique initial swarms...\")\n",
    "            for i in range(num_pso_runs):\n",
    "                # Split the key for this run to ensure unique randomness\n",
    "                current_key, subkey = random.split(current_key)\n",
    "\n",
    "                # Generate initial positions using JAX PRNG within bounds\n",
    "                # Use jnp arrays for min/max bounds in jax.random.uniform\n",
    "                min_bound_jnp = jnp.full(n_params, -10.0, dtype=jnp.float64)\n",
    "                max_bound_jnp = jnp.full(n_params, 10.0, dtype=jnp.float64)\n",
    "                init_pos_jax = random.uniform(subkey,\n",
    "                                              shape=(swarmsize, n_params),\n",
    "                                              dtype=jnp.float64,\n",
    "                                              minval=min_bound_jnp,\n",
    "                                              maxval=max_bound_jnp)\n",
    "                # Convert to NumPy array for pyswarms\n",
    "                init_pos_np = np.array(init_pos_jax)\n",
    "\n",
    "                print(f\"  PSO Run {i+1}/{num_pso_runs} (using JAX key split for init_pos)\")\n",
    "                optimizer = ps.single.GlobalBestPSO(n_particles=swarmsize,\n",
    "                                                     dimensions=n_params,\n",
    "                                                     options=options,\n",
    "                                                     bounds=bounds,\n",
    "                                                     # Pass the generated initial positions\n",
    "                                                     init_pos=init_pos_np) # <-- Pass init_pos here\n",
    "\n",
    "                # Perform optimization (pyswarms will use the provided init_pos)\n",
    "                current_pso_loss, current_pso_params = optimizer.optimize(\n",
    "                    pso_objective_wrapper,\n",
    "                    iters=pso_iters,\n",
    "                    verbose=False\n",
    "                )\n",
    "                current_pso_params = jnp.array(current_pso_params, dtype=jnp.float64)\n",
    "\n",
    "                print(f\"    Run {i+1} completed. Loss: {current_pso_loss}\")\n",
    "                if current_pso_loss < best_pso_loss:\n",
    "                    best_pso_loss = current_pso_loss\n",
    "                    best_pso_params = current_pso_params\n",
    "                    print(f\"    New best PSO loss found: {best_pso_loss}\")\n",
    "\n",
    "            # ... (rest of the function: handling no solution, BFGS refinement) ...\n",
    "            if best_pso_params is None:\n",
    "                 print(\"Warning: PSO did not find any valid solution after multiple runs. Using initial guess for BFGS.\")\n",
    "                 best_pso_params = initial_guess # Fallback\n",
    "\n",
    "            print(f\"\\nBest PSO loss after {num_pso_runs} runs: {best_pso_loss}\")\n",
    "            print(\"Refining best PSO result with BFGS...\")\n",
    "\n",
    "            result = minimize(objective_fn, jnp.array(best_pso_params),\n",
    "                              method='BFGS', options={'maxiter': 500})\n",
    "\n",
    "            if not result.success:\n",
    "                 print(f\"BFGS refinement failed: {result.message}\")\n",
    "                 return best_pso_params # Return PSO best\n",
    "\n",
    "            print(f\"BFGS refinement successful. Final loss: {result.fun}\")\n",
    "            return result.x\n",
    "\n",
    "\n",
    "\n",
    "    # 敏感度分析模块\n",
    "    def calculate_sensitivities(opt_params, base_loss):\n",
    "        mask = 1 - jnp.eye(MAX_NPARAMS)\n",
    "        \n",
    "        @jit      \n",
    "        def batch_loss(params_matrix):\n",
    "            return vmap(loss_fn)(params_matrix * mask)\n",
    "\n",
    "        def sensitivity_objective(flat_params):\n",
    "            matrix_params = flat_params.reshape(MAX_NPARAMS, MAX_NPARAMS)\n",
    "            return jnp.sum(batch_loss(matrix_params))\n",
    "\n",
    "        try:\n",
    "            initial_flat = (opt_params * mask).flatten()\n",
    "            optimized_flat = run_optimization(sensitivity_objective, initial_flat, key=opt_key, num_pso_runs=5)\n",
    "            optimized_matrix = optimized_flat.reshape(MAX_NPARAMS, MAX_NPARAMS)\n",
    "            losses = batch_loss(optimized_matrix)\n",
    "            relative_loss = jnp.log2(losses / base_loss)\n",
    "            return relative_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Sensitivity analysis error: {str(e)}\")\n",
    "            return jnp.zeros(MAX_NPARAMS, dtype=jnp.float64)\n",
    "\n",
    "\n",
    "    # 主流程\n",
    "    # Main execution flow\n",
    "    try:\n",
    "        # Split the master key for the main optimization run\n",
    "        opt_key, sensi_key = random.split(master_key) # Keep keys separate if needed later\n",
    "\n",
    "        optimized_params = run_optimization(loss_fn, params, key=opt_key, num_pso_runs=5) # Pass the key\n",
    "        if optimized_params is None:\n",
    "             print(\"Optimization failed to produce parameters.\")\n",
    "             return None\n",
    "\n",
    "        final_loss = loss_fn(optimized_params)\n",
    "        print(f\"Final optimized loss: {final_loss}\")\n",
    "    except Exception as e:\n",
    "        # ... (error handling remains the same) ...\n",
    "        print(f\"Optimization or final loss calculation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "    if not jnp.isfinite(final_loss):\n",
    "        print(\"Final loss is not finite.\")\n",
    "        return None\n",
    "\n",
    "    # Pass a key to sensitivity analysis if it also needs randomness\n",
    "    # For now, assuming calculate_sensitivities doesn't need a separate key\n",
    "    sensitivities = calculate_sensitivities(optimized_params, final_loss)\n",
    "    sensitivity_dict = {f\"sensitive of params[{i}]\": round(float(sensitivities[i]), 4) \n",
    "                       for i in range(len(sensitivities))}\n",
    "\n",
    "\n",
    "    return {\n",
    "        'params': optimized_params,\n",
    "        'loss': final_loss,\n",
    "        'sensitivities': sensitivity_dict\n",
    "    }\n",
    "\n",
    "\n",
    "@jit\n",
    "def equation(q: jnp.array, p: jnp.array, params: jnp.array) -> jnp.array:\n",
    "    q = q[...,0]\n",
    "    p = p[...,0]\n",
    "\n",
    "    #T = params[1] * jnp.square(p)\n",
    "    #V =  params[3] * jnp.square(q) +params[0]*q +params[2]\n",
    "\n",
    "    T = params[1] * jnp.square(p) \n",
    "    V = params[3] * jnp.cos(params[2]*q)+params[0]\n",
    "\n",
    "    return T + V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d109448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
